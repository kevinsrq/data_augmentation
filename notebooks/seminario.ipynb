{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Versão do torchtext que foi utilizada é a 0.6.0\n",
    "# -----------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchtext\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "from random import randint\n",
    "from googletrans import Translator\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações Gerais\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se conjunto está ok\n",
    "\n",
    "df = pd.read_csv('Caminho')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo para parafrasear o conjunto de dados com o modelo pré-treinado gpt-3.\n",
    "# Aceita somente o inglês, utilizado a base de spam.\n",
    "\n",
    "openai.api_key='Chave'\n",
    "\n",
    "new = []\n",
    "sentence = \"Rewrite a phrase preserving their original meaning: \" \n",
    "\n",
    "for i in range (0,232):\n",
    "    var = df[df.index == i]\n",
    "    var = var['Mensagem'].to_string() # Mudar atributo de acordo com o conjunto\n",
    "    var = re.sub(\"^\\d+\\s\", \"\",var).strip()\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=sentence+var,\n",
    "        temperature=0,\n",
    "        max_tokens=500,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    \n",
    "    aux = response.choices[0].text[2:]\n",
    "    new.append(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo Random Deletion para o conjunto Livraria\n",
    "\n",
    "new = []\n",
    "\n",
    "for i in range(0,1163):\n",
    "    var = df[df.index == i]\n",
    "    var = var['Titulo'].to_string() \n",
    "    var = re.sub(\"^\\d+\\s\", \"\",var).strip()\n",
    "    spl = var.split()\n",
    "    if len(spl) > 1:\n",
    "        if len(spl) <= 5:\n",
    "            rand = randint(0,len(spl)-1)\n",
    "            spl.pop(rand)\n",
    "            aux = ' '.join(spl)\n",
    "            new.append(aux)\n",
    "        else:\n",
    "            for n in range(0,4):\n",
    "                rand = randint(0,len(spl)-1)\n",
    "                spl.pop(rand)\n",
    "            aux = ' '.join(spl)\n",
    "            new.append(aux)\n",
    "    else:\n",
    "        new.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo Random Deletion para o conjunto de spam\n",
    "\n",
    "new = []\n",
    "\n",
    "for i in range(0,232):\n",
    "    var = df[df.index == i]\n",
    "    var = var['Mensagem'].to_string() \n",
    "    var = re.sub(\"^\\d+\\s\", \"\",var).strip()\n",
    "    spl = var.split()\n",
    "    if len(spl) > 1:\n",
    "        if len(spl) <= 5:\n",
    "            rand = randint(0,len(spl)-1)\n",
    "            spl.pop(rand)\n",
    "            aux = ' '.join(spl)\n",
    "            new.append(aux)\n",
    "        elif len(spl) <= 35:\n",
    "            for n in range(0,4):\n",
    "                rand = randint(0,len(spl)-1)\n",
    "                spl.pop(rand)\n",
    "            aux = ' '.join(spl)\n",
    "            new.append(aux)\n",
    "        else:\n",
    "            for n in range(0,10):\n",
    "                rand = randint(0,len(spl)-1)\n",
    "                spl.pop(rand)\n",
    "            aux = ' '.join(spl)\n",
    "            new.append(aux)\n",
    "    else:\n",
    "        new.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo back-translation\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "new = []\n",
    "\n",
    "for i in range(0,232): # tamanho do conjunto\n",
    "    var = df[df.index == i]\n",
    "    var = var['Titulo'].to_string() # Mudar atributo de acordo com o conjunto\n",
    "    var = re.sub(\"^\\d+\\s\", \"\",var).strip()\n",
    "    trans1 = translator.translate(var, dest='pt', src='en').text\n",
    "    trans2 = translator.translate(trans1, dest='en', src='pt').text\n",
    "    new.append(trans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo Random Swap\n",
    "\n",
    "new = []\n",
    "\n",
    "for i in range(0,1163): # tamanho do conjunto\n",
    "    var = df[df.index == i]\n",
    "    var = var['Titulo'].to_string() # Mudar atributo de acordo com o conjunto\n",
    "    var = re.sub(\"^\\d+\\s\", \"\",var).strip()\n",
    "    spl = var.split()\n",
    "    if len(spl) > 1:\n",
    "        for n in range(0,2):\n",
    "            rand1 = randint(0,len(spl)-1)\n",
    "            rand2 = randint(0,len(spl)-1)\n",
    "            aux1 = spl.pop(rand1)\n",
    "            spl.insert(rand2, aux1)\n",
    "        aux2 = ' '.join(spl)\n",
    "        new.append(aux2)\n",
    "    else:\n",
    "        new.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depois de aplicado os algoritmos de data augmentation o mesmo é transformado em um novo dataframe\n",
    "\n",
    "novo = pd.DataFrame(new)\n",
    "novo['Genero'] = df['Genero'] # Substituir atributo de acordo com dataset\n",
    "novo.rename(columns={0: 'Titulo'}, inplace = True) \n",
    "\n",
    "fim = df.append(novo, ignore_index=True)\n",
    "\n",
    "# embaralhar as novas amostras\n",
    "fim = fim.sample(frac = 1)\n",
    "\n",
    "fim = fim.reset_index(drop=True)\n",
    "\n",
    "# Salvar o conjunto com as novas amostras\n",
    "fim.to_csv('Caminho', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar o conjunto de dados para o torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o processamento dos atributos\n",
    "\n",
    "TEXT = torchtext.data.Field(\n",
    "    tokenize='spacy', # Por padrão separa por espaços em branco\n",
    "    tokenizer_language='pt_core_news_sm' # 'en_core_web_sm' inglês / pt_core_news_sm pt\n",
    ")\n",
    "\n",
    "# Definindo o processamento do Rótulo\n",
    "\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o conjunto train para utilização no torchtext\n",
    "\n",
    "fields = [('Titulo', TEXT), ('Genero', LABEL)]\n",
    "\n",
    "train_data = torchtext.data.TabularDataset(\n",
    "    path='trainLivraria+BackTranslation.csv', format='csv',\n",
    "    skip_header=True, fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o conjunto test para utilização no torchtext\n",
    "\n",
    "fields = [('Titulo', TEXT), ('Genero', LABEL)]\n",
    "\n",
    "test_data = torchtext.data.TabularDataset(\n",
    "    path='testLivraria+BackTranslation.csv', format='csv',\n",
    "    skip_header=True, fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uma linha de como ficou o conjunto\n",
    "\n",
    "print(vars(test_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o vocabulário\n",
    "\n",
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f'Tamanho vocabulário: {len(TEXT.vocab)}')\n",
    "print(f'Número de classes: {len(LABEL.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palavras mais frequentes e a sua contagem\n",
    "\n",
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os números atribuidos para cada classe\n",
    "\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de amostras por classe\n",
    "\n",
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os Data Loaders\n",
    "\n",
    "train_loader ,test_loader = \\\n",
    "        torchtext.data.BucketIterator.splits( # Melhores batches com bucketiterator\n",
    "        (train_data, test_data),\n",
    "         batch_size=BATCH_SIZE,\n",
    "         sort_within_batch=True,\n",
    "         sort_key=lambda x: len(x.Titulo),\n",
    "         device=DEVICE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "for batch in train_loader:\n",
    "    print(f'Tamanho da matriz de texto: {batch.Titulo.size()}')\n",
    "    print(f'Tamanho do vetor de classe: {batch.Genero.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nTest:')\n",
    "for batch in test_loader:\n",
    "    print(f'Tamanho da matriz de texto: {batch.Titulo.size()}')\n",
    "    print(f'Tamanho do vetor de classe: {batch.Genero.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Construção do Modelo LSTM\n",
    "\n",
    "class RNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim)        \n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, text):\n",
    "        #  dimensão do text: [sentence length, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        #  dimensão embedded: [sentence length, batch size, embedding dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        #  dimensão output: [sentence length, batch size, hidden dim]\n",
    "        #  dimensão hidden: [1, batch size, hidden dim]\n",
    "\n",
    "        hidden.squeeze_(0)\n",
    "        #  dimensão hidden: [batch size, hidden dim]\n",
    "        \n",
    "        output = self.fc(hidden)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o modelo\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = RNN(input_dim=len(TEXT.vocab),\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            output_dim=NUM_CLASSES\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Utilização do otimizador Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para computar a acurácia do modelo, tanto para treinamento quanto para teste\n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "            \n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do conjunto\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "treinamento = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        \n",
    "        text = batch_data.Titulo.to(DEVICE) # Mudar atributo de acordo com dataset\n",
    "        labels = batch_data.Genero.to(DEVICE) # Mudar atributo de acordo com dataset\n",
    " \n",
    "        # FORWARD AND BACK PROP\n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Atualizar os parâmetros do modelo\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Imprimindo Época / Tamanho do Batch / Loss\n",
    "        print (f'Época: {epoch+1}/{NUM_EPOCHS} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        resultado = compute_accuracy(model, train_loader, DEVICE)\n",
    "        print(f'Acurácia Treinamento: 'f'{resultado:.2f}%')\n",
    "        treinamento.append(resultado.item())\n",
    "        \n",
    "    print(f'Tempo decorrido: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Tempo total decorrido: {(time.time() - start_time)/60:.2f} min')\n",
    "\n",
    "# Depois de treinar o modelo com as repectivas épocas, mostrar a acurácia no conjunto de teste\n",
    "print(f'Acurácia de Teste: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando gráficamente a acurácia para cada época respectiva\n",
    "\n",
    "epocas = [range(1, 31)] # Número de épocas utilizadas + 1\n",
    "\n",
    "fig = px.line(x = epocas, y = treinamento, title='Treinamento Livraria + Back Translation')\n",
    "fig.update_yaxes(title='Acurácia')\n",
    "fig.update_xaxes(title='Épocas')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo com um novo exemplo\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"pt\")\n",
    "\n",
    "def predict(model, sentence):\n",
    "\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
    "    prediction = torch.max(prediction, 1)\n",
    "    return prediction\n",
    "\n",
    "predict(model, \"Um livro histórico\") # Exemplo para a base livraria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
