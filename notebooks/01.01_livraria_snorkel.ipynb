{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snorkel Apply\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Data Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.augmentation import transformation_function\n",
    "from snorkel.augmentation import ApplyOnePolicy, PandasTFApplier\n",
    "from snorkel.slicing import slicing_function, PandasSFApplier\n",
    "\n",
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>genero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iniciação ao Estudo da Administração</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iniciação a Administração geral</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iniciação a Administração de pessoal</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Administração de Materiais</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gestão Ambiental na Empresa</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 titulo         genero\n",
       "0  Iniciação ao Estudo da Administração  Administracao\n",
       "1       Iniciação a Administração geral  Administracao\n",
       "2  Iniciação a Administração de pessoal  Administracao\n",
       "3            Administração de Materiais  Administracao\n",
       "4           Gestão Ambiental na Empresa  Administracao"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df = pd.read_csv('../data/livros.csv')\n",
    "books_df.columns = books_df.columns.map(str.lower)\n",
    "books_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 02. Data Analysis\n",
    "One way to understand the content of a text is to perform an analysis of the most essential words, that is, those that occur more frequently and have greater meaning for the topic addressed.\n",
    "\n",
    "Due to the nature of the data set, the titles usually consist of few words and have a limited number of examples, which allows a more subjective analysis to identify which words may be relevant in the classification of the main topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download Portuguese stopwords from the NLTK library\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_special_characters_and_stopwords(text):\n",
    "    \"\"\"\n",
    "    Removes special characters (except Latin usual characters),\n",
    "    tokenizes the text, and removes Portuguese stopwords.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to process.\n",
    "        \n",
    "    Returns:\n",
    "        list of str: A list of cleaned and tokenized words without stopwords.\n",
    "    \"\"\"\n",
    "    # Remove special characters (except Latin usual characters)\n",
    "    clean_text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Remove accents and diacritics from the text (e.g., converting é to e)\n",
    "    clean_text = unidecode(clean_text)\n",
    "    \n",
    "    # Tokenize the cleaned text into a list of words\n",
    "    clean_text = clean_text.strip().split()\n",
    "\n",
    "    # Get the list of Portuguese stopwords\n",
    "    stopwords_list = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    # Remove stopwords from the tokenized words\n",
    "    clean_text = [word.lower() for word in clean_text if word.lower() not in stopwords_list]\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['alt_title'] = books_df['titulo'].map(remove_special_characters_and_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Administracao',\n",
       " 'Artes',\n",
       " 'Biologia',\n",
       " 'Geografia',\n",
       " 'Historia',\n",
       " 'Literatura',\n",
       " 'Matematica']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(books_df['genero'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genero</th>\n",
       "      <th>alt_title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Historia</td>\n",
       "      <td>historia</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>Historia</td>\n",
       "      <td>brasil</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Historia</td>\n",
       "      <td>geral</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Historia</td>\n",
       "      <td>arte</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Historia</td>\n",
       "      <td>guerra</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Historia</td>\n",
       "      <td>documentos</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Historia</td>\n",
       "      <td>indios</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Historia</td>\n",
       "      <td>indigenas</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Historia</td>\n",
       "      <td>leste</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Historia</td>\n",
       "      <td>privada</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       genero   alt_title  count\n",
       "800  Historia    historia    154\n",
       "801  Historia      brasil     79\n",
       "802  Historia       geral     30\n",
       "803  Historia        arte     22\n",
       "804  Historia      guerra     19\n",
       "..        ...         ...    ...\n",
       "895  Historia  documentos      3\n",
       "896  Historia      indios      3\n",
       "897  Historia   indigenas      3\n",
       "898  Historia       leste      3\n",
       "899  Historia     privada      3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the 'genero' and 'alt_title' columns from the DataFrame\n",
    "# and explode the 'alt_title' column to create multiple rows for each title\n",
    "# Then we can see the most relevant words for each genero\n",
    "(\n",
    " books_df[['genero', 'alt_title']]\n",
    " .explode('alt_title')\n",
    " \n",
    " # Group the data by 'genero', reset the index, and calculate the value counts\n",
    " .groupby(by='genero', as_index=False)\n",
    " .value_counts()\n",
    " \n",
    " # Sort the values in descending order first by 'genero' and then by 'count'\n",
    " .sort_values(by=['genero', 'count'], ascending=False)\n",
    " \n",
    " # Group the sorted data by 'genero' and select the top 15 elements for each group\n",
    " .groupby('genero')\n",
    " .head(100)\n",
    "\n",
    "# Change the word inside the double quotes for selection\n",
    ").query('genero==\"Historia\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.01. Analysis Conclusions:\n",
    "\n",
    "We will use the Snorkel package for data augmentation, which uses simple concepts to make a heuristic inference. After removing the stop words and cleaning the words, it is possible to select some keywords that can strongly indicate a genre.\n",
    "\n",
    "These analyses and selections do not have exact criteria. Therefore, if you are viewing the code, you may find one or another word more relevant than the ones selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Administração | Artes   | Biologia   | Geografia  | História    | Literatura | Matemática  |\n",
    "|---------------|---------|------------|------------|-------------|------------|-------------|\n",
    "| administracao | museu   | biologia   | geografia  | historia    | literatura | matematica  |\n",
    "| organizacoes  | pintura | seres      | geografico | guerra      | texto      | fundamentos |\n",
    "| organizacao   | arte    | genetica   | sociedade  | revolucao   | portuguesa | geometria   |\n",
    "| gestao        | teatro  | vida       | regiao     | anos        | leitura    | calculo     |\n",
    "| empresa       | museum  | biologicas | territorio | civilizacao | gramatica  | analitica   |\n",
    "|               | gallery | evolucao   |            | antiga      |            | financeira  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 03. Snorkel\n",
    "The Snorkel Python package is a system that allows the fast generation of training data with weak supervision. It was created to automate the process of creating and managing training data, allowing users to label, build and manage training data programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {'Historia' : 0, 'Administração' : 1, 'Geografia' : 2, \n",
    "          'Biologia' : 3, 'Matemática' : 4, 'Artes': 5, 'Literatura': 6}\n",
    "\n",
    "# books_df['label'] = books_df['genero'].map(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.01. Train and Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test = train_test_split(books_df, test_size=0.25, random_state=42, stratify=books_df['genero'])\n",
    "\n",
    "# Reset the index of the training and testing sets\n",
    "x_train.reset_index(drop=True, inplace=True) \n",
    "x_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the words in the 'alt_title' column of the training set into a single string\n",
    "x_train['alt_title'] = x_train['alt_title'].map(lambda x: ' '.join(x))\n",
    "\n",
    "# Join the words in the 'alt_title' column of the testing set into a single string\n",
    "x_test['alt_title'] = x_test['alt_title'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.02. Labeling Function\n",
    "\n",
    "The labeling_function function in Snorkel is used to create weak labeling functions that assign labels to data instances. These labeling functions are often written by human experts and are based on rules. These functions are used to generate approximate or weakly supervised labels for the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "# Define a labeling function for the \"Historia\" label\n",
    "@labeling_function()\n",
    "def lf_historia(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Historia\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Historia\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Historia\" label\n",
    "    historia_keywords = [\"guerra\", \"revol\", \"anos\", \"civiliz\", \"antiga\", \n",
    "                         \"hist\", \"arqueo\", \"arquitetura\", \"cultura\", \"brasil\", \"polit\",\n",
    "                         \"socie\", \"socioe\", \"amer\", \"geral\", \"indep\", \"imperi\", \"repub\", \n",
    "                         \"reforma\", \"mediev\", \"moderna\", \"contempo\", \"europeia\",\"idade\", \n",
    "                         \"colonial\", \"nacion\", \"africa\", \"colon\", \"descobri\", \"escrav\", \n",
    "                         \"crise\", 'ociden', \"doc\", \"antig\"]    \n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in historia_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Historia']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1 \n",
    "\n",
    "@labeling_function()\n",
    "def lf_administracao(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Administração\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Administração\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Administração\" label\n",
    "    \n",
    "    administracao_keywords = [\"adm\", \"org\", \"gest\", \"empr\", \"neg\", \"econ\", \"controle\"]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in administracao_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Administracao']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match    return -1\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Geografia\" label\n",
    "@labeling_function()\n",
    "def lf_geografia(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Geografia\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Geografia\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Geografia\" label\n",
    "    geografia_keywords = [\"geo\", \"socio\", \"antropo\", \"regiao\", \"terr\", \"rural\", \"urban\", \n",
    "                          'mund', 'atlas', 'mapa', 'carto', 'clima', 'ambien', 'ecolo', 'hidro',]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in geografia_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Geografia']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Biologia\" label\n",
    "@labeling_function()\n",
    "def lf_biologia(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Biologia\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Biologia\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Biologia\" label\n",
    "    biologia_keywords = [\"bio\", \"seres\", \"vida\", \"evol\", \"genet\", \"medic\", \"saude\", \n",
    "                         \"nutri\", \"fisio\", \"enferm\", \"farma\", \"veteri\",\"odonto\", \"psico\"]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in biologia_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Biologia']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Literatura\" label\n",
    "@labeling_function()\n",
    "def lf_literatura(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Literatura\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Literatura\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Literatura\" label\n",
    "    literatura_keywords = [\"litera\", \"texto\", \"portuguesa\", \"leit\", \"grama\", \"poesia\", \"poema\"]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in literatura_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Literatura']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Artes\" label\n",
    "@labeling_function()\n",
    "def lf_artes(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Artes\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Artes\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Artes\" label\n",
    "    artes_keywords = [\"museu\", \"cinema\", \"filme\", \"museum\", \"gallery\",\n",
    "                      \"art\", \"pintur\", \"escult\", \"music\", \"teatr\", \"danc\"]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in artes_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Artes']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Matemática\" label\n",
    "@labeling_function()\n",
    "def lf_matematica(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Matemática\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Matemática\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Matemática\" label\n",
    "    matematica_keywords = [\"matema\", \"fundam\", \"calcu\", \"algebra\", \"geome\", \"estatis\", \n",
    "                           \"proba\", \"trigono\", \"logica\", \"fisica\", 'analit', 'aplica', \n",
    "                           \"medio\", \"grau\", 'discre', 'numeri', 'vetor', 'equa', 'difer', 'integral']\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in matematica_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Matematica']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [00:18<00:00, 46.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the missing variables\n",
    "LABELS = {'Historia': 0, 'Administracao': 1, 'Geografia': 2, 'Biologia': 3, \n",
    "          'Literatura': 4, 'Artes': 5, 'Matematica': 6}\n",
    "\n",
    "# Apply the labeling functions to the training data\n",
    "applier = PandasLFApplier(lfs=[lf_historia, lf_administracao, lf_geografia, lf_biologia, \n",
    "                               lf_literatura, lf_artes, lf_matematica])\n",
    "L_train = applier.apply(df=x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.178]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.178]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.178]\n",
      "INFO:root:[60 epochs]: TRAIN:[loss=0.178]\n",
      " 67%|██████▋   | 67/100 [00:00<00:00, 668.09epoch/s]INFO:root:[80 epochs]: TRAIN:[loss=0.177]\n",
      "100%|██████████| 100/100 [00:00<00:00, 652.00epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 291/291 [00:05<00:00, 55.78it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the label model\n",
    "label_model = LabelModel(cardinality=7, verbose=True)\n",
    "label_model.fit(L_train=L_train, \n",
    "                n_epochs=100, \n",
    "                lr=0.000005,\n",
    "                log_freq=20, \n",
    "                seed=42, optimizer='adam')\n",
    "\n",
    "# Predict labels for the training data\n",
    "x_train['label_inf'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")\n",
    "\n",
    "# Apply the labeling functions to the test data\n",
    "L_train = applier.apply(df=x_test)\n",
    "\n",
    "# Predict labels for the test data\n",
    "x_test['label_inf'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['label'] = x_train['genero'].map(LABELS).values\n",
    "x_test['label'] = x_test['genero'].map(LABELS).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label_inf</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label_inf  -1   0   1   2   3   4   5   6\n",
       "label                                    \n",
       "0          28  78   1   5   1   0   3   0\n",
       "1          11   9  17   0   1   0   1   0\n",
       "2           2  18   0  12   0   1   0   0\n",
       "3           4   5   0   3  22   0   0   0\n",
       "4           2   6   0   0   0   5   0   0\n",
       "5          12   3   0   1   0   0   6   0\n",
       "6           1   2   1   3   0   0   0  27"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(x_test['label'], x_test['label_inf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.03. Transformation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_aug = naw.ContextualWordEmbsAug(model_path='neuralmind/bert-base-portuguese-cased', aug_min=1)\n",
    "\n",
    "def synonym_replacer(text, model=context_aug):\n",
    "    \"\"\"\n",
    "    This function takes in a string of text and performs data augmentation using the specified augmentation technique.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): A string of text to be augmented.\n",
    "    \n",
    "    Returns:\n",
    "    str: The augmented text.\n",
    "    \"\"\"\n",
    "    # Define the augmentation technique\n",
    "    aug = model\n",
    "    \n",
    "    return aug.augment(text)[0]\n",
    "\n",
    "@transformation_function()\n",
    "def tf_synonym(df_row): \n",
    "    # Assuming that 'alt_title' is the column containing text\n",
    "    df_row['alt_title'] = synonym_replacer(df_row.alt_title)\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [05:54<00:00,  2.46it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_policy = ApplyOnePolicy(n_per_original=2, keep_original=True)\n",
    "tf_applier = PandasTFApplier([tf_synonym], tf_policy)\n",
    "\n",
    "x_train_aug = tf_applier.apply(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2616/2616 [00:49<00:00, 53.15it/s]\n"
     ]
    }
   ],
   "source": [
    "L_train = applier.apply(df=x_train_aug.drop('label_inf', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.087]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.010]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[60 epochs]: TRAIN:[loss=0.000]\n",
      " 68%|██████▊   | 68/100 [00:00<00:00, 676.15epoch/s]INFO:root:[80 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 100/100 [00:00<00:00, 620.45epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_model = LabelModel(cardinality=7, verbose=True)\n",
    "label_model.fit(L_train=L_train, \n",
    "                n_epochs=100, \n",
    "                lr=0.1,\n",
    "                log_freq=20, \n",
    "                seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/291 [00:00<00:07, 38.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 52.48it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_aug['label_inf'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")\n",
    "\n",
    "# Apply the labeling functions to the test data\n",
    "L_train = applier.apply(df=x_test)\n",
    "\n",
    "# Predict labels for the test data\n",
    "x_test['label_inf'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label_inf</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label_inf  -1   0   1   2   3   4   5   6\n",
       "label                                    \n",
       "0          28  75   1   6   1   0   4   1\n",
       "1          11   4  21   0   2   0   1   0\n",
       "2           2  18   0  11   0   1   0   1\n",
       "3           4   3   0   3  24   0   0   0\n",
       "4           2   6   0   0   0   5   0   0\n",
       "5          12   4   0   0   0   0   6   0\n",
       "6           1   0   1   3   1   1   0  27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(x_train_aug['label'], x_train_aug['label_inf'], margins=True)\n",
    "pd.crosstab(x_test['label'], x_test['label_inf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2616/2616 [00:00<00:00, 25221.71it/s]\n"
     ]
    }
   ],
   "source": [
    "@slicing_function()\n",
    "def sf_historia(x):\n",
    "    return 1 if \"histori\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_administracao(x):\n",
    "    return 1 if \"administra\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_geografia(x):\n",
    "    return 1 if \"geogra\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_biologia(x):\n",
    "    return 1 if \"biolo\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_literatura(x):\n",
    "    return 1 if \"litera\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_artes(x):\n",
    "    return 1 if \"arte\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_matematica(x):\n",
    "    return 1 if \"matem\" in x.alt_title.lower() else 0\n",
    "\n",
    "\n",
    "sf_applier = PandasSFApplier([sf_historia, sf_administracao, sf_geografia, \n",
    "                              sf_biologia, sf_literatura, sf_artes, sf_matematica])\n",
    "slice_labels = sf_applier.apply(x_train_aug)\n",
    "\n",
    "# slice_labels = pd.DataFrame(slice_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = x_train_aug.reset_index(drop=True).join(pd.DataFrame(slice_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = x_test.reset_index(drop=True).join(pd.DataFrame(slice_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['label'] = x_train['genero'].map(LABELS)\n",
    "x_train_aug['label'] = x_train_aug['genero'].map(LABELS)\n",
    "x_train_final['label'] = x_train_final['genero'].map(LABELS)\n",
    "x_test_final['label'] = x_test['genero'].map(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(['titulo', 'genero'], axis=1, inplace=True)\n",
    "x_train_aug.drop(['titulo', 'genero'], axis=1, inplace=True)\n",
    "x_train_final.drop(['titulo', 'genero'], axis=1, inplace=True)\n",
    "x_test_final.drop(['titulo', 'genero'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv('../data/processed/train_og.csv', index=False)\n",
    "x_train_aug.to_csv('../data/processed/train_aug.csv', index=False)\n",
    "x_train_final.to_csv('../data/processed/train_final.csv', index=False)\n",
    "x_test_final.to_csv('../data/processed/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
