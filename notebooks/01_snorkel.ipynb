{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilização do Snorkel \n",
    "--- \n",
    "### 01. Import da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>genero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iniciação ao Estudo da Administração</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iniciação a Administração geral</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iniciação a Administração de pessoal</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Administração de Materiais</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gestão Ambiental na Empresa</td>\n",
       "      <td>Administracao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 titulo         genero\n",
       "0  Iniciação ao Estudo da Administração  Administracao\n",
       "1       Iniciação a Administração geral  Administracao\n",
       "2  Iniciação a Administração de pessoal  Administracao\n",
       "3            Administração de Materiais  Administracao\n",
       "4           Gestão Ambiental na Empresa  Administracao"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df = pd.read_csv('../data/livros.csv')\n",
    "books_df.columns = books_df.columns.map(str.lower)\n",
    "books_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### 02. Análise da Base \n",
    "\n",
    "\"Uma maneira de compreender o conteúdo de um texto é realizar uma análise das palavras mais essenciais, ou seja, aquelas que ocorrem com maior frequência e possuem maior significado para o tema abordado. \n",
    "\n",
    "Devido à natureza da base de dados, os títulos geralmente consistem em poucas palavras e têm uma quantidade limitada de exemplos, o que possibilita uma análise mais subjetiva para identificar quais palavras podem ser relevantes na classificação do tópico principal.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from unidecode import unidecode \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "# Download Portuguese stopwords from the NLTK library\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_special_characters_and_stopwords(text):\n",
    "    \"\"\"\n",
    "    Removes special characters (except Latin usual characters),\n",
    "    tokenizes the text, and removes Portuguese stopwords.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to process.\n",
    "        \n",
    "    Returns:\n",
    "        list of str: A list of cleaned and tokenized words without stopwords.\n",
    "    \"\"\"\n",
    "    # Remove special characters (except Latin usual characters)\n",
    "    clean_text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Remove accents and diacritics from the text (e.g., converting é to e)\n",
    "    clean_text = unidecode(clean_text)\n",
    "    \n",
    "    # Tokenize the cleaned text into a list of words\n",
    "    clean_text = clean_text.strip().split()\n",
    "\n",
    "    # Get the list of Portuguese stopwords\n",
    "    stopwords_list = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    # Remove stopwords from the tokenized words\n",
    "    clean_text = [word.lower() for word in clean_text if word.lower() not in stopwords_list]\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['alt_title'] = books_df['titulo'].map(remove_special_characters_and_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Administracao',\n",
       " 'Artes',\n",
       " 'Biologia',\n",
       " 'Geografia',\n",
       " 'Historia',\n",
       " 'Literatura',\n",
       " 'Matematica']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(books_df['genero'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genero</th>\n",
       "      <th>alt_title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Historia</td>\n",
       "      <td>historia</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>Historia</td>\n",
       "      <td>brasil</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Historia</td>\n",
       "      <td>geral</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Historia</td>\n",
       "      <td>arte</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Historia</td>\n",
       "      <td>guerra</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Historia</td>\n",
       "      <td>documentos</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Historia</td>\n",
       "      <td>indios</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Historia</td>\n",
       "      <td>indigenas</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Historia</td>\n",
       "      <td>leste</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Historia</td>\n",
       "      <td>privada</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       genero   alt_title  count\n",
       "800  Historia    historia    154\n",
       "801  Historia      brasil     79\n",
       "802  Historia       geral     30\n",
       "803  Historia        arte     22\n",
       "804  Historia      guerra     19\n",
       "..        ...         ...    ...\n",
       "895  Historia  documentos      3\n",
       "896  Historia      indios      3\n",
       "897  Historia   indigenas      3\n",
       "898  Historia       leste      3\n",
       "899  Historia     privada      3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the 'genero' and 'alt_title' columns from the DataFrame\n",
    "# and explode the 'alt_title' column to create multiple rows for each title\n",
    "# Then we can see the most relevant words for each genero\n",
    "(\n",
    " books_df[['genero', 'alt_title']]\n",
    " .explode('alt_title')\n",
    " \n",
    " # Group the data by 'genero', reset the index, and calculate the value counts\n",
    " .groupby(by='genero', as_index=False)\n",
    " .value_counts()\n",
    " \n",
    " # Sort the values in descending order first by 'genero' and then by 'count'\n",
    " .sort_values(by=['genero', 'count'], ascending=False)\n",
    " \n",
    " # Group the sorted data by 'genero' and select the top 15 elements for each group\n",
    " .groupby('genero')\n",
    " .head(100)\n",
    "\n",
    "# Change the word inside the double quotes for selection\n",
    ").query('genero==\"Historia\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.01. Conclusões de análises: \n",
    "\n",
    "Iremos utilizar o pacote Snorkel para data augmentation, que utiliza conceitos simples \n",
    "para fazer uma inferência heurística. Após a remoção das stop words e limpeza das palavras, \n",
    "é possível selecionar algumas palavras-chave que podem fortemente indicar um gênero.\n",
    "\n",
    "Essas análises e seleções não possuem critérios exatos. Portanto, caso você esteja vendo \n",
    "o código, é possível que você ache uma ou outra palavra mais relevante do que as selecionadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Administração | Artes   | Biologia   | Geografia  | História    | Literatura | Matemática  |\n",
    "|---------------|---------|------------|------------|-------------|------------|-------------|\n",
    "| administracao | museu   | biologia   | geografia  | historia    | literatura | matematica  |\n",
    "| organizacoes  | pintura | seres      | geografico | guerra      | texto      | fundamentos |\n",
    "| organizacao   | arte    | genetica   | sociedade  | revolucao   | portuguesa | geometria   |\n",
    "| gestao        | teatro  | vida       | regiao     | anos        | leitura    | calculo     |\n",
    "| empresa       | museum  | biologicas | territorio | civilizacao | gramatica  | analitica   |\n",
    "|               | gallery | evolucao   |            | antiga      |            | financeira  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 03. Snorkel\n",
    "\n",
    "O pacote Snorkel do Python é um sistema que permite a geração rápida de dados de treinamento com supervisão fraca. Ele foi criado para automatizar o processo de criação e gerenciamento de dados de treinamento, permitindo que os usuários rotulem, construam e gerenciem dados de treinamento programaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {'Historia' : 0, 'Administração' : 1, 'Geografia' : 2, \n",
    "          'Biologia' : 3, 'Matemática' : 4, 'Artes': 5, 'Literatura': 6}\n",
    "\n",
    "# books_df['label'] = books_df['genero'].map(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.01 Teste e treino para o modelo de Weak Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test = train_test_split(books_df, test_size=0.25, random_state=42, stratify=books_df['genero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['alt_title'] = x_train['alt_title'].map(lambda x: ' '.join(x))\n",
    "x_test['alt_title'] = x_test['alt_title'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.02. Função de Rotulação \n",
    "\n",
    "A função labeling_function no Snorkel é usada para criar funções de rotulagem fracas que \n",
    "atribuem rótulos a instâncias de dados. Essas funções de rotulagem são frequentemente \n",
    "escritas por especialistas humanos e são baseadas em regras. Essas funções são usadas para \n",
    "gerar rótulos aproximados ou fracamente supervisionados para os dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "# Define a labeling function for the \"Historia\" label\n",
    "@labeling_function()\n",
    "def lf_historia(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Historia\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Historia\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Historia\" label\n",
    "    historia_keywords = [\"guerra\", \"revol\", \"anos\", \"civiliz\", \"antiga\", \n",
    "                         \"hist\", \"arqueo\", \"arquitetura\", \"cultura\", \"brasil\", \"polit\",\n",
    "                         \"socie\", \"socioe\", \"amer\", \"geral\", \"indep\", \"imperi\", \"repub\", \n",
    "                         \"reforma\", \"mediev\", \"moderna\", \"contempo\", \"europeia\",\"idade\", \n",
    "                         \"colonial\", \"nacion\", \"africa\", \"colon\", \"descobri\", \"escrav\", \n",
    "                         \"crise\", 'ociden', \"doc\", \"antig\"]    \n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in historia_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Historia']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1 \n",
    "\n",
    "@labeling_function()\n",
    "def lf_administracao(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Administração\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Administração\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Administração\" label\n",
    "    \n",
    "    administracao_keywords = [\"adm\", \"org\", \"gest\", \"empr\", \"neg\", \"econ\", \"controle\"]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in administracao_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Administracao']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match    return -1\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Geografia\" label\n",
    "@labeling_function()\n",
    "def lf_geografia(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Geografia\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Geografia\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Geografia\" label\n",
    "    geografia_keywords = [\"geo\", \"socio\", \"antropo\", \"regiao\", \"terr\", \"rural\", \"urban\", \n",
    "                          'mund', 'atlas', 'mapa', 'carto', 'clima', 'ambien', 'ecolo', 'hidro',]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in geografia_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Geografia']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n",
    "\n",
    "\n",
    "# Define a labeling function for the \"Biologia\" label\n",
    "@labeling_function()\n",
    "def lf_biologia(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Biologia\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Biologia\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Biologia\" label\n",
    "    biologia_keywords = [\"bio\", \"seres\", \"vida\", \"evol\", \"genet\", \"medic\", \"saude\", \n",
    "                         \"nutri\", \"fisio\", \"enferm\", \"farma\", \"veteri\",\"odonto\", \"psico\"]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in biologia_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Biologia']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Literatura\" label\n",
    "@labeling_function()\n",
    "def lf_literatura(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Literatura\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Literatura\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Literatura\" label\n",
    "    literatura_keywords = [\"litera\", \"texto\", \"portuguesa\", \"leit\", \"grama\", \"poesia\", \"poema\"]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in literatura_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in  words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Literatura']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Artes\" label\n",
    "@labeling_function()\n",
    "def lf_artes(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Artes\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Artes\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Artes\" label\n",
    "    artes_keywords = [\"museu\", \"cinema\", \"filme\", \"museum\", \"gallery\",\n",
    "                      \"art\", \"pintur\", \"escult\", \"music\", \"teatr\", \"danc\"]\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in artes_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Artes']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n",
    "\n",
    "# Define a labeling function for the \"Matemática\" label\n",
    "@labeling_function()\n",
    "def lf_matematica(words: str):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns the \"Matemática\" label if any of the keywords for this label are present\n",
    "    in the input words. If none of the keywords match, it returns -1 to represent \"no label\".\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): A list of strings representing the words to be checked for keywords.\n",
    "    \n",
    "    Returns:\n",
    "    int: An integer representing the \"Matemática\" label, or -1 if no match is found.\n",
    "    \"\"\"\n",
    "    # Define a list of keywords for the \"Matemática\" label\n",
    "    matematica_keywords = [\"matema\", \"fundam\", \"calcu\", \"algebra\", \"geome\", \"estatis\", \n",
    "                           \"proba\", \"trigono\", \"logica\", \"fisica\", 'analit', 'aplica', \n",
    "                           \"medio\", \"grau\", 'discre', 'numeri', 'vetor', 'equa', 'difer', 'integral']\n",
    "    # Check if any of the keywords are present in the input words\n",
    "    for word in matematica_keywords:\n",
    "        if remove_special_characters_and_stopwords(word)[0] in words['alt_title']:\n",
    "            # Return the corresponding label if a match is found\n",
    "            return LABELS['Matematica']\n",
    "    # Return -1 to represent \"no label\" if none of the keywords match\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [00:16<00:00, 52.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "# Define the missing variables\n",
    "LABELS = {'Historia': 0, 'Administracao': 1, 'Geografia': 2, 'Biologia': 3, \n",
    "          'Literatura': 4, 'Artes': 5, 'Matematica': 6}\n",
    "\n",
    "# Apply the labeling functions to the training data\n",
    "applier = PandasLFApplier(lfs=[lf_historia, lf_administracao, lf_geografia, lf_biologia, \n",
    "                               lf_literatura, lf_artes, lf_matematica])\n",
    "L_train = applier.apply(df=x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.178]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.070]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.030]\n",
      " 53%|█████▎    | 53/100 [00:00<00:00, 520.52epoch/s]INFO:root:[60 epochs]: TRAIN:[loss=0.011]\n",
      "INFO:root:[80 epochs]: TRAIN:[loss=0.005]\n",
      "100%|██████████| 100/100 [00:00<00:00, 446.49epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 291/291 [00:05<00:00, 52.86it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the label model\n",
    "label_model = LabelModel(cardinality=7, verbose=True)\n",
    "label_model.fit(L_train=L_train, \n",
    "                n_epochs=100, \n",
    "                lr=0.005,\n",
    "                log_freq=20, \n",
    "                seed=42, optimizer='adam')\n",
    "\n",
    "# Predict labels for the training data\n",
    "x_train['label_inf'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")\n",
    "\n",
    "# Apply the labeling functions to the test data\n",
    "L_train = applier.apply(df=x_test)\n",
    "\n",
    "# Predict labels for the test data\n",
    "x_test['label_inf'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['label'] = x_train['genero'].map(LABELS).values\n",
    "x_test['label'] = x_test['genero'].map(LABELS).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label_inf</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>190</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label_inf   -1    0   1   2   3   4   5   6\n",
       "label                                      \n",
       "0          110  190   5   5  29   1   3   5\n",
       "1           24   12  76   0   2   0   1   3\n",
       "2           12   51   2  34   0   0   0   0\n",
       "3           19   13   4   4  59   0   0   3\n",
       "4           10   16   0   0   0  13   0   1\n",
       "5           23   12   0   0   0   0  30   0\n",
       "6           11    2   3  12   3   0   1  68"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(x_test['label'], x_test['label_inf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.03. Função de Transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "from snorkel.augmentation import transformation_function\n",
    "\n",
    "# Initialize augmenters\n",
    "# synonym_aug = naw.SynonymAug(lang='por', aug_min=1)\n",
    "context_aug = naw.ContextualWordEmbsAug(model_path='../model/bert/', aug_min=1)\n",
    "\n",
    "def synonym_replacer(text, model=context_aug):\n",
    "    \"\"\"\n",
    "    This function takes in a string of text and performs data augmentation using the specified augmentation technique.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): A string of text to be augmented.\n",
    "    \n",
    "    Returns:\n",
    "    str: The augmented text.\n",
    "    \"\"\"\n",
    "    # Define the augmentation technique\n",
    "    aug = model\n",
    "    \n",
    "    return aug.augment(text)[0]\n",
    "\n",
    "@transformation_function()\n",
    "def tf_synonym(df_row): \n",
    "    # Assuming that 'alt_title' is the column containing text\n",
    "    df_row['alt_title'] = synonym_replacer(df_row.alt_title)\n",
    "    return df_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [09:36<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.augmentation import ApplyOnePolicy, PandasTFApplier\n",
    "\n",
    "tf_policy = ApplyOnePolicy(n_per_original=3, keep_original=True)\n",
    "tf_applier = PandasTFApplier([tf_synonym], tf_policy)\n",
    "\n",
    "x_train_aug = tf_applier.apply(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3488/3488 [01:13<00:00, 47.61it/s]\n"
     ]
    }
   ],
   "source": [
    "L_train = applier.apply(df=x_train_aug.drop('label_inf', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.080]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.010]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.001]\n",
      " 58%|█████▊    | 58/100 [00:00<00:00, 574.31epoch/s]INFO:root:[60 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[80 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 100/100 [00:00<00:00, 543.51epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_model = LabelModel(cardinality=7, verbose=True)\n",
    "label_model.fit(L_train=L_train, \n",
    "                n_epochs=100, \n",
    "                lr=0.1,\n",
    "                log_freq=20, \n",
    "                seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 52.99it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_aug['label_inf'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")\n",
    "\n",
    "# Apply the labeling functions to the test data\n",
    "L_train = applier.apply(df=x_test)\n",
    "\n",
    "# Predict labels for the test data\n",
    "x_test['label_inf'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label_inf</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label_inf  -1   0   1   2   3   4   5   6\n",
       "label                                    \n",
       "0          28  75   1   6   1   0   4   1\n",
       "1          11   3  21   0   3   0   1   0\n",
       "2           2  18   0  11   0   1   0   1\n",
       "3           4   3   0   3  24   0   0   0\n",
       "4           2   6   0   0   0   5   0   0\n",
       "5          12   4   0   0   0   0   6   0\n",
       "6           1   0   1   3   1   1   0  27"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(x_train_aug['label'], x_train_aug['label_inf'], margins=True)\n",
    "pd.crosstab(x_test['label'], x_test['label_inf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3488/3488 [00:00<00:00, 27138.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.slicing import slicing_function, PandasSFApplier \n",
    "\n",
    "@slicing_function()\n",
    "def sf_historia(x):\n",
    "    return 1 if \"histori\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_administracao(x):\n",
    "    return 1 if \"administra\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_geografia(x):\n",
    "    return 1 if \"geogra\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_biologia(x):\n",
    "    return 1 if \"biolo\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_literatura(x):\n",
    "    return 1 if \"litera\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_artes(x):\n",
    "    return 1 if \"arte\" in x.alt_title.lower() else 0\n",
    "\n",
    "@slicing_function()\n",
    "def sf_matematica(x):\n",
    "    return 1 if \"matem\" in x.alt_title.lower() else 0\n",
    "\n",
    "\n",
    "sf_applier = PandasSFApplier([sf_historia, sf_administracao, sf_geografia, \n",
    "                              sf_biologia, sf_literatura, sf_artes, sf_matematica])\n",
    "slice_labels = sf_applier.apply(x_train_aug)\n",
    "\n",
    "# slice_labels = pd.DataFrame(slice_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = x_train_aug.reset_index(drop=True).join(pd.DataFrame(slice_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = x_test.reset_index(drop=True).join(pd.DataFrame(slice_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export das bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'genero'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'genero'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kevin\\OneDrive\\Documents\\GitHub\\data_augmentation\\notebooks\\01_snorkel.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kevin/OneDrive/Documents/GitHub/data_augmentation/notebooks/01_snorkel.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_train[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m x_train[\u001b[39m'\u001b[39;49m\u001b[39mgenero\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmap(LABELS)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/OneDrive/Documents/GitHub/data_augmentation/notebooks/01_snorkel.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x_train_aug[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m x_train_aug[\u001b[39m'\u001b[39m\u001b[39mgenero\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(LABELS)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/OneDrive/Documents/GitHub/data_augmentation/notebooks/01_snorkel.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x_train_final[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m x_train_final[\u001b[39m'\u001b[39m\u001b[39mgenero\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(LABELS)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'genero'"
     ]
    }
   ],
   "source": [
    "x_train['label'] = x_train['genero'].map(LABELS)\n",
    "x_train_aug['label'] = x_train_aug['genero'].map(LABELS)\n",
    "x_train_final['label'] = x_train_final['genero'].map(LABELS)\n",
    "x_test['label'] = x_test['genero'].map(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['titulo', 'genero'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kevin\\OneDrive\\Documents\\GitHub\\data_augmentation\\notebooks\\01_snorkel.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kevin/OneDrive/Documents/GitHub/data_augmentation/notebooks/01_snorkel.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_train\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mtitulo\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgenero\u001b[39;49m\u001b[39m'\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/OneDrive/Documents/GitHub/data_augmentation/notebooks/01_snorkel.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x_train_aug\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mtitulo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgenero\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/OneDrive/Documents/GitHub/data_augmentation/notebooks/01_snorkel.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x_train_final\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mtitulo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgenero\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['titulo', 'genero'] not found in axis\""
     ]
    }
   ],
   "source": [
    "x_train.drop(['titulo', 'genero'], axis=1, inplace=True)\n",
    "x_train_aug.drop(['titulo', 'genero'], axis=1, inplace=True)\n",
    "x_train_final.drop(['titulo', 'genero'], axis=1, inplace=True)\n",
    "x_test.drop(['titulo', 'genero'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv('../data/processed/train_og.csv', index=False)\n",
    "x_train_aug.to_csv('../data/processed/train_aug.csv', index=False)\n",
    "x_train_final.to_csv('../data/processed/train_final.csv', index=False)\n",
    "x_test_final.to_csv('../data/processed/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
