{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchtext\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random\n",
    "import time\n",
    "from random import randint\n",
    "from googletrans import Translator\n",
    "import re\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'chave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 20\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anything lor if they all go then i go lor...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For taking part in our mobile survey yesterday...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65-321\\n\\nPRIVATE! Your 2003 Account Statement...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bears Pic Nick, and Tom, Pete and ... Dick. In...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does uncle timi help in clearing cars</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>URGENT! Your mobile was awarded a å£1,500 Bonu...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Sorry, I'll call you  later. I am in meeting sir.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Get the Nokia tone for your mobile phone absol...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>I'm having a bite to eat now, but I'll be head...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>He's crazy that he's married, but I like good-...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem Classe\n",
       "0         Anything lor if they all go then i go lor...    ham\n",
       "1    For taking part in our mobile survey yesterday...   spam\n",
       "2    65-321\\n\\nPRIVATE! Your 2003 Account Statement...   spam\n",
       "3    Bears Pic Nick, and Tom, Pete and ... Dick. In...   spam\n",
       "4                Does uncle timi help in clearing cars    ham\n",
       "..                                                 ...    ...\n",
       "459  URGENT! Your mobile was awarded a å£1,500 Bonu...   spam\n",
       "460  Sorry, I'll call you  later. I am in meeting sir.    ham\n",
       "461  Get the Nokia tone for your mobile phone absol...   spam\n",
       "462  I'm having a bite to eat now, but I'll be head...    ham\n",
       "463  He's crazy that he's married, but I like good-...    ham\n",
       "\n",
       "[464 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam6.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paraprhasing with pre-trained model gpt-3\n",
    "\n",
    "j = 0\n",
    "new = []\n",
    "sentence = \"Rewrite a phrase preserving their original meaning: \" \n",
    "\n",
    "for i in range (230,232):\n",
    "    var = df[df.index == j]\n",
    "    var = var['Mensagem'].to_string()\n",
    "    var = re.sub(\"^\\d+\\s\", \"\",var).strip()\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=sentence+var,\n",
    "        temperature=0,\n",
    "        max_tokens=500,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    \n",
    "    aux = response.choices[0].text[2:]\n",
    "    new.append(aux)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Deletion\n",
    "\n",
    "j = 0\n",
    "new = []\n",
    "\n",
    "for i in range(0,232):\n",
    "    var = df[df.index == j]\n",
    "    var = var['Mensagem'].to_string()\n",
    "    var = re.sub(\"^\\d+\\s\", \"\",var).strip()\n",
    "    spl = var.split()\n",
    "    if len(spl) <= 5:\n",
    "        rand = randint(0,len(spl)-1)\n",
    "        spl.pop(rand)\n",
    "        aux = ' '.join(spl)\n",
    "        new.append(aux)\n",
    "    elif len(spl) <= 20:\n",
    "        for n in range(0,5):\n",
    "            rand = randint(0,len(spl)-1)\n",
    "            spl.pop(rand)\n",
    "        aux = ' '.join(spl)\n",
    "        new.append(aux)\n",
    "    elif len(spl) <= 50:\n",
    "        for n in range(0,15):\n",
    "            rand = randint(0,len(spl)-1)\n",
    "            spl.pop(rand)\n",
    "        aux = ' '.join(spl)\n",
    "        new.append(aux)\n",
    "    else:\n",
    "        for n in range(0,40):\n",
    "            rand = randint(0,len(spl)-1)\n",
    "            spl.pop(rand)\n",
    "        aux = ' '.join(spl)\n",
    "        new.append(aux)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back translation\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "j = 0\n",
    "new = []\n",
    "\n",
    "for i in range(0,232):\n",
    "    var = df[df.index == j]\n",
    "    var = var['Mensagem'].to_string()\n",
    "    var = re.sub(\"^\\d+\\s\", \"\",var).strip()\n",
    "    trans1 = translator.translate(var, dest='pt', src='en').text\n",
    "    trans2 = translator.translate(trans1, dest='en', src='pt').text\n",
    "    new.append(trans2)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Swap\n",
    "\n",
    "j = 0\n",
    "new = []\n",
    "\n",
    "for i in range(0,232):\n",
    "    var = df[df.index == j]\n",
    "    var = var['Mensagem'].to_string()\n",
    "    var = var[1:].strip()\n",
    "    spl = var.split()\n",
    "    for n in range(0,2):\n",
    "        rand1 = randint(0,len(spl)-1)\n",
    "        rand2 = randint(0,len(spl)-1)\n",
    "        aux1 = spl.pop(rand1)\n",
    "        spl.insert(rand2, aux1)\n",
    "    aux2 = ' '.join(spl)\n",
    "    new.append(aux2)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo = pd.DataFrame(new)\n",
    "novo['Classe'] = df['Classe']\n",
    "novo.rename(columns={0: 'Mensagem'}, inplace = True)\n",
    "novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo = novo.drop(232)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fim = df.append(novo, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fim = fim.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fim = fim.reset_index(drop=True)\n",
    "fim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fim.to_csv('spam6.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = df.sample(n = 1250)\n",
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(out.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(out.index)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.reset_index(drop=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('spam3.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[['Mensagem', 'Classe']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the feature processing\n",
    "\n",
    "TEXT = torchtext.data.Field(\n",
    "    tokenize='spacy', # default splits on whitespace\n",
    "    tokenizer_language='en_core_web_sm'\n",
    ")\n",
    "\n",
    "### Defining the label processing\n",
    "\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('Mensagem', TEXT), ('Classe', LABEL)]\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path='spam6.csv', format='csv',\n",
    "    skip_header=True, fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 371\n",
      "Num Test: 93\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = dataset.split(\n",
    "    split_ratio=[0.8, 0.2],\n",
    "    random_state=random.seed(RANDOM_SEED))\n",
    "\n",
    "print(f'Num Train: {len(train_data)}')\n",
    "print(f'Num Test: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mensagem': ['Purchase', 'a', 'pizza', ',', 'either', 'Meat', 'Lovers', 'or', 'Supreme', '.'], 'Classe': 'ham'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2095\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f'Vocabulary size: {len(TEXT.vocab)}')\n",
    "print(f'Number of classes: {len(LABEL.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 319), ('to', 174), (',', 169), ('!', 151), ('a', 108), ('you', 106), ('I', 91), ('?', 78), ('...', 70), ('for', 69), ('the', 68), ('is', 64), ('your', 56), ('have', 53), ('and', 48), ('are', 41), ('2', 39), ('/', 39), (\"'s\", 38), ('on', 38)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '.', 'to', ',', '!', 'a', 'you', 'I', '?']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10]) # itos = integer-to-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'ham': 0, 'spam': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ham': 193, 'spam': 178})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader ,test_loader = \\\n",
    "        torchtext.data.BucketIterator.splits(\n",
    "        (train_data, test_data),\n",
    "         batch_size=BATCH_SIZE,\n",
    "         sort_within_batch=False,\n",
    "         sort_key=lambda x: len(x.Mensagem),\n",
    "         device=DEVICE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate(train_loader):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train')\n",
    "for batch in train_loader:\n",
    "    print(f'Text matrix size: {batch.Mensagem.size()}')\n",
    "    print(f'Target vector size: {batch.Classe.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nTest:')\n",
    "for batch in test_loader:\n",
    "    print(f'Text matrix size: {batch.Mensagem.size()}')\n",
    "    print(f'Target vector size: {batch.Classe.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        #self.rnn = torch.nn.RNN(embedding_dim,\n",
    "        #                        hidden_dim,\n",
    "        #                        nonlinearity='relu')\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim)        \n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, text):\n",
    "        # text dim: [sentence length, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        # embedded dim: [sentence length, batch size, embedding dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        # output dim: [sentence length, batch size, hidden dim]\n",
    "        # hidden dim: [1, batch size, hidden dim]\n",
    "\n",
    "        hidden.squeeze_(0)\n",
    "        # hidden dim: [batch size, hidden dim]\n",
    "        \n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(2095, 100)\n",
      "  (rnn): LSTM(100, 256)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(input_dim=len(TEXT.vocab),\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            output_dim=NUM_CLASSES # could use 1 for binary classification\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "            \n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 | Batch 000/004 | Loss: 0.4373\n",
      "Epoch: 001/020 | Batch 001/004 | Loss: 0.4643\n",
      "Epoch: 001/020 | Batch 002/004 | Loss: 0.3099\n",
      "Epoch: 001/020 | Batch 003/004 | Loss: 0.3340\n",
      "training accuracy: 94.34%\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 002/020 | Batch 000/004 | Loss: 0.2984\n",
      "Epoch: 002/020 | Batch 001/004 | Loss: 0.3278\n",
      "Epoch: 002/020 | Batch 002/004 | Loss: 0.3217\n",
      "Epoch: 002/020 | Batch 003/004 | Loss: 0.3304\n",
      "training accuracy: 94.07%\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 003/020 | Batch 000/004 | Loss: 0.2357\n",
      "Epoch: 003/020 | Batch 001/004 | Loss: 0.1984\n",
      "Epoch: 003/020 | Batch 002/004 | Loss: 0.2137\n",
      "Epoch: 003/020 | Batch 003/004 | Loss: 0.2195\n",
      "training accuracy: 96.23%\n",
      "Time elapsed: 0.06 min\n",
      "Epoch: 004/020 | Batch 000/004 | Loss: 0.1454\n",
      "Epoch: 004/020 | Batch 001/004 | Loss: 0.1224\n",
      "Epoch: 004/020 | Batch 002/004 | Loss: 0.1181\n",
      "Epoch: 004/020 | Batch 003/004 | Loss: 0.1556\n",
      "training accuracy: 99.19%\n",
      "Time elapsed: 0.07 min\n",
      "Epoch: 005/020 | Batch 000/004 | Loss: 0.0813\n",
      "Epoch: 005/020 | Batch 001/004 | Loss: 0.0977\n",
      "Epoch: 005/020 | Batch 002/004 | Loss: 0.0946\n",
      "Epoch: 005/020 | Batch 003/004 | Loss: 0.0816\n",
      "training accuracy: 99.19%\n",
      "Time elapsed: 0.09 min\n",
      "Epoch: 006/020 | Batch 000/004 | Loss: 0.0735\n",
      "Epoch: 006/020 | Batch 001/004 | Loss: 0.0935\n",
      "Epoch: 006/020 | Batch 002/004 | Loss: 0.0321\n",
      "Epoch: 006/020 | Batch 003/004 | Loss: 0.0290\n",
      "training accuracy: 99.73%\n",
      "Time elapsed: 0.11 min\n",
      "Epoch: 007/020 | Batch 000/004 | Loss: 0.0247\n",
      "Epoch: 007/020 | Batch 001/004 | Loss: 0.0575\n",
      "Epoch: 007/020 | Batch 002/004 | Loss: 0.0180\n",
      "Epoch: 007/020 | Batch 003/004 | Loss: 0.0176\n",
      "training accuracy: 99.73%\n",
      "Time elapsed: 0.13 min\n",
      "Epoch: 008/020 | Batch 000/004 | Loss: 0.0148\n",
      "Epoch: 008/020 | Batch 001/004 | Loss: 0.0121\n",
      "Epoch: 008/020 | Batch 002/004 | Loss: 0.0345\n",
      "Epoch: 008/020 | Batch 003/004 | Loss: 0.0098\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.14 min\n",
      "Epoch: 009/020 | Batch 000/004 | Loss: 0.0087\n",
      "Epoch: 009/020 | Batch 001/004 | Loss: 0.0086\n",
      "Epoch: 009/020 | Batch 002/004 | Loss: 0.0071\n",
      "Epoch: 009/020 | Batch 003/004 | Loss: 0.0074\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.16 min\n",
      "Epoch: 010/020 | Batch 000/004 | Loss: 0.0055\n",
      "Epoch: 010/020 | Batch 001/004 | Loss: 0.0048\n",
      "Epoch: 010/020 | Batch 002/004 | Loss: 0.0047\n",
      "Epoch: 010/020 | Batch 003/004 | Loss: 0.0044\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.18 min\n",
      "Epoch: 011/020 | Batch 000/004 | Loss: 0.0035\n",
      "Epoch: 011/020 | Batch 001/004 | Loss: 0.0032\n",
      "Epoch: 011/020 | Batch 002/004 | Loss: 0.0034\n",
      "Epoch: 011/020 | Batch 003/004 | Loss: 0.0031\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.20 min\n",
      "Epoch: 012/020 | Batch 000/004 | Loss: 0.0031\n",
      "Epoch: 012/020 | Batch 001/004 | Loss: 0.0025\n",
      "Epoch: 012/020 | Batch 002/004 | Loss: 0.0023\n",
      "Epoch: 012/020 | Batch 003/004 | Loss: 0.0025\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.22 min\n",
      "Epoch: 013/020 | Batch 000/004 | Loss: 0.0020\n",
      "Epoch: 013/020 | Batch 001/004 | Loss: 0.0019\n",
      "Epoch: 013/020 | Batch 002/004 | Loss: 0.0020\n",
      "Epoch: 013/020 | Batch 003/004 | Loss: 0.0019\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.25 min\n",
      "Epoch: 014/020 | Batch 000/004 | Loss: 0.0019\n",
      "Epoch: 014/020 | Batch 001/004 | Loss: 0.0016\n",
      "Epoch: 014/020 | Batch 002/004 | Loss: 0.0017\n",
      "Epoch: 014/020 | Batch 003/004 | Loss: 0.0014\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.26 min\n",
      "Epoch: 015/020 | Batch 000/004 | Loss: 0.0018\n",
      "Epoch: 015/020 | Batch 001/004 | Loss: 0.0013\n",
      "Epoch: 015/020 | Batch 002/004 | Loss: 0.0014\n",
      "Epoch: 015/020 | Batch 003/004 | Loss: 0.0012\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.28 min\n",
      "Epoch: 016/020 | Batch 000/004 | Loss: 0.0012\n",
      "Epoch: 016/020 | Batch 001/004 | Loss: 0.0013\n",
      "Epoch: 016/020 | Batch 002/004 | Loss: 0.0013\n",
      "Epoch: 016/020 | Batch 003/004 | Loss: 0.0010\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.30 min\n",
      "Epoch: 017/020 | Batch 000/004 | Loss: 0.0019\n",
      "Epoch: 017/020 | Batch 001/004 | Loss: 0.0010\n",
      "Epoch: 017/020 | Batch 002/004 | Loss: 0.0010\n",
      "Epoch: 017/020 | Batch 003/004 | Loss: 0.0010\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.32 min\n",
      "Epoch: 018/020 | Batch 000/004 | Loss: 0.0009\n",
      "Epoch: 018/020 | Batch 001/004 | Loss: 0.0010\n",
      "Epoch: 018/020 | Batch 002/004 | Loss: 0.0009\n",
      "Epoch: 018/020 | Batch 003/004 | Loss: 0.0009\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.33 min\n",
      "Epoch: 019/020 | Batch 000/004 | Loss: 0.0008\n",
      "Epoch: 019/020 | Batch 001/004 | Loss: 0.0009\n",
      "Epoch: 019/020 | Batch 002/004 | Loss: 0.0008\n",
      "Epoch: 019/020 | Batch 003/004 | Loss: 0.0008\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.35 min\n",
      "Epoch: 020/020 | Batch 000/004 | Loss: 0.0008\n",
      "Epoch: 020/020 | Batch 001/004 | Loss: 0.0007\n",
      "Epoch: 020/020 | Batch 002/004 | Loss: 0.0007\n",
      "Epoch: 020/020 | Batch 003/004 | Loss: 0.0008\n",
      "training accuracy: 100.00%\n",
      "Time elapsed: 0.37 min\n",
      "Total Training Time: 0.37 min\n",
      "Test accuracy: 91.40%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        \n",
    "        text = batch_data.Mensagem.to(DEVICE)\n",
    "        labels = batch_data.Classe.to(DEVICE)\n",
    "\n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: 'f'{compute_accuracy(model, train_loader, DEVICE):.2f}%')\n",
    "        \n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def predict(model, sentence):\n",
    "\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
    "    prediction = torch.max(prediction, 1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, \"do you want a gift, click here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
